Job Application for Research Engineer, Responsible Engineering at DeepMind Apply Now Research Engineer, Responsible Engineering at DeepMind London, UK At Google DeepMind, we value diversity of experience, knowledge, backgrounds and perspectives and harness these qualities to create extraordinary impact. We are committed to equal employment opportunity regardless of sex, race, religion or belief, ethnic or national origin, disability, age, citizenship, marital, domestic or civil partnership status, sexual orientation, gender identity, pregnancy, or related condition (including breastfeeding) or any other basis as protected by applicable law. If you have a disability or additional need that requires accommodation, please do not hesitate to let us know. Snapshot We are looking for REs to join the responsible engineering team in Google DeepMind's Foundational Research Team. Powerful next-generation AI systems are in the pipeline; system builders and operators will need foundational theory, methods, and practices to make them safer, more trustworthy, and easier to align with overall benefit to the public. Responsible AI, which seeks those traits, is a growing, hugely interdisciplinary field that needs contributors from all backgrounds: join us and help evolve both AI and AI engineering towards a richer and more conscientious proficiency. About us Artificial Intelligence could be one of humanity’s most transformative inventions. At Google DeepMind, we’re a team of scientists, engineers, machine learning experts and more, working together to advance the state of the art in artificial intelligence. We use our technologies for widespread public benefit and scientific discovery, and collaborate with others on critical challenges, ensuring safety and ethics are the highest priority. Based in the Foundational Research Unit, the Responsible Engineering Team enhances Google DeepMind’s frontier AI research with current and novel responsible AI tools and concepts, working to build systems that are fundamentally safer, more mishap-resistant, and more practical to deploy in the real world. Working alongside scientists and engineers from all parts of the organisation, we perform experimental research on novel algorithmic methods, scale them from prototypes to large-scale systems, and collaborate on integrating them with applications towards scientific progress or product impact. We work by collaborating widely across units and project areas, bringing technical leadership and expertise to our projects, pushing on key research problems, and disseminating knowledge and practices across GDM as a strong part of the engineering community. We have created a passionate and engaging culture, combining research and engineering environments, to provide a supportive balance of structure and flexibility. Our approach encourages collaboration across research groups, leading to ambitious creativity and the scope for innovative research breakthroughs. The role As part of the Responsible Engineering team, you will work with your teammates and project collaborators on research and systems for machine learning research and its applications. You’ll learn/extend, adapt, and operationalise relevant interdisciplinary knowledge (sociotechnical AI, HCI, ML interpretability, public policy, the list grows constantly) toward AI projects — at all stages of the AI development pipeline but with a particular focus on earlier, more exploratory research. In all projects, you’ll mix proactive imagination and creativity with our team’s lengthy practical experience, both to predict and mitigate new and familiar harms, and to see and exploit opportunities for more socially beneficial AI systems. Key responsibilities As a research engineer, you will bring a combination of engineering and research skills to the task of advancing GDM’s mission. Depending on the requirements of a project, you will be responsible for some of the following: Develop research or product prototypes, generating research ideas and collaboratively iterating on their improvement, e.g. by reading and reproducing existing papers, identifying and applying key insights in new contexts, or combining them in novel ways. Perform and analyse experiments, and scale up experimentally successful algorithms. Build tools and infrastructure in support of research projects, e.g. by surveying the technical landscape, identifying and deploying suitable existing tools, or designing new solutions. Act as a bridge between research and engineering, bringing engineering expertise into research projects and research experience into engineering of tools and frameworks. Collaborate and communicate ideas, plans and outcomes (orally and in writing) within projects and with adjacent teams, aligning work and timelines with affected teams, sharing insights and reviewing others' work to achieve milestones. Champion engineering best practices within and around the team, e.g. by improving workflows, promoting code reviews, mentoring on code readability, etc. Propose direction and advise on projects according to your individual experience and expertise. Proactively share your individual skills and knowledge, and collaboratively upskill adjacent engineers and researchers. Skills and experience that will help you, or that you will be able to grow in this role are: Python-based ML/scientific libraries such as JAX, PyTorch, TensorFlow, NumPy, ... Research literacy (mathematics and statistics, understanding of research papers, ...) Large-scale system design, distributed systems Effective collaboration and communication (discussion, presentation, technical and research writing, whiteboard sessions, ...) Familiarity with contemporary social impacts and risks/opportunities (short- and long-term) of real-world AI system deployment. Gathering data and feedback on AI systems from human raters. Responsible AI is a new and broad field, making it difficult to name additional specific skill items. However it manifests concretely for you, your general interest in topics like the following can be of use: How deployment of new technologies affects large social systems; how impactful technologies affect and are affected by (and are) culture. The professional responsibilities of AI system developers and deployers. Large-scale AI systems and the natural environment. Making interdisciplinary topics accessible to technical audiences. Curiosity about the internal workings of large neural networks and other machine learning models. Note: In the event your application is successful and an offer of employment is made to you, any offer of employment will be conditional on the results of a background check, performed by a third party acting on our behalf. For more information on how we handle your data, please see our Applicant and Candidate Privacy Policy. Apply for this Job * Required First Name * Last Name * Email * Phone Resume/CV * Drop files here Attach Dropbox Google Drive or enter manually (File types: pdf, doc, docx, txt, rtf) Cover Letter Drop files here Attach Dropbox Google Drive or enter manually (File types: pdf, doc, docx, txt, rtf) LinkedIn Profile Link to external profile e.g. LinkedIn, GitHub etc. Where did you hear about this role? * Please selectDeepMind website Glassdoor University LinkedIn Twitter Instagram I am a participant on the Deepmind Scholarship program Attraction and Engagement I know someone at DeepMind Grace Hopper Conference NeurIPS Conference Other Please indicate your race/ethnic group: * Choose all that apply Asian Black/African descent Hispanic/Latino/Latinx (e.g. identify as Hispanic or Latino with ties in Latin America, and can be of any race) Indigenous (e.g. Aboriginal Australian, Alaska Native, First Nations, Native American, Native Hawaiian, Samonan) Middle Eastern/North African White/European descent Prefer not to say Please indicate your gender: * DeepMind is committed to equal opportunity employment regardless of race, religion or belief, ethnic or national origin, disability, age, citizenship, marital status, domestic or civil partnership status, sexual orientation, gender identity or any other basis as protected by applicable law. A voluntary self-identification question enables us to monitor and evaluate the effectiveness of our equal opportunities policy within our recruitment process. Your information is used in an aggregated form for these limited purposes and will not form part of your application. Disclosure is voluntary and the information you provide will be kept confidential in compliance with our Applicant and Candidate Privacy Policy found at https://careers.google.com/privacy-policy/ Please selectWoman Man Non-binary Prefer not to say You're in charge of responsible AI for a company that makes a conversational AI-powered search and retrieval system for video data. Can you name some potential customers for a product like this, then describe some technical characteristics that you'd like your product to possess in order for it to be suitable for those applications from a responsibility standpoint? * Our system has flagged this application as potentially being associated with bot traffic. Please turn off any VPNs, clear your browser cache and cookies, or try submitting your application in a different browser. If this issue persists, please reach out to our support team via our help center. Please complete the reCAPTCHA above. Powered by Read our Privacy Policy